{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embeddings: Semantics of the language\n",
    "\n",
    "We have some sentences and want to compare the semantic distance of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sentence-transformers\n",
      "  Downloading sentence_transformers-3.4.1-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting transformers<5.0.0,>=4.41.0 (from sentence-transformers)\n",
      "  Using cached transformers-4.49.0-py3-none-any.whl.metadata (44 kB)\n",
      "Requirement already satisfied: tqdm in /Users/christianweyer/Sources/gen-ai-customer-workshop-november-2024/.conda/lib/python3.11/site-packages (from sentence-transformers) (4.67.1)\n",
      "Collecting torch>=1.11.0 (from sentence-transformers)\n",
      "  Using cached torch-2.6.0-cp311-none-macosx_11_0_arm64.whl.metadata (28 kB)\n",
      "Collecting scikit-learn (from sentence-transformers)\n",
      "  Using cached scikit_learn-1.6.1-cp311-cp311-macosx_12_0_arm64.whl.metadata (31 kB)\n",
      "Collecting scipy (from sentence-transformers)\n",
      "  Using cached scipy-1.15.2-cp311-cp311-macosx_14_0_arm64.whl.metadata (61 kB)\n",
      "Collecting huggingface-hub>=0.20.0 (from sentence-transformers)\n",
      "  Downloading huggingface_hub-0.29.3-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting Pillow (from sentence-transformers)\n",
      "  Using cached pillow-11.1.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (9.1 kB)\n",
      "Collecting filelock (from huggingface-hub>=0.20.0->sentence-transformers)\n",
      "  Downloading filelock-3.18.0-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting fsspec>=2023.5.0 (from huggingface-hub>=0.20.0->sentence-transformers)\n",
      "  Downloading fsspec-2025.3.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: packaging>=20.9 in /Users/christianweyer/Sources/gen-ai-customer-workshop-november-2024/.conda/lib/python3.11/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/christianweyer/Sources/gen-ai-customer-workshop-november-2024/.conda/lib/python3.11/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\n",
      "Requirement already satisfied: requests in /Users/christianweyer/Sources/gen-ai-customer-workshop-november-2024/.conda/lib/python3.11/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/christianweyer/Sources/gen-ai-customer-workshop-november-2024/.conda/lib/python3.11/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (4.12.2)\n",
      "Collecting networkx (from torch>=1.11.0->sentence-transformers)\n",
      "  Using cached networkx-3.4.2-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: jinja2 in /Users/christianweyer/Sources/gen-ai-customer-workshop-november-2024/.conda/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
      "Collecting sympy==1.13.1 (from torch>=1.11.0->sentence-transformers)\n",
      "  Using cached sympy-1.13.1-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy==1.13.1->torch>=1.11.0->sentence-transformers)\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/christianweyer/Sources/gen-ai-customer-workshop-november-2024/.conda/lib/python3.11/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2.2.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/christianweyer/Sources/gen-ai-customer-workshop-november-2024/.conda/lib/python3.11/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
      "Collecting tokenizers<0.22,>=0.21 (from transformers<5.0.0,>=4.41.0->sentence-transformers)\n",
      "  Downloading tokenizers-0.21.1-cp39-abi3-macosx_11_0_arm64.whl.metadata (6.8 kB)\n",
      "Collecting safetensors>=0.4.1 (from transformers<5.0.0,>=4.41.0->sentence-transformers)\n",
      "  Using cached safetensors-0.5.3-cp38-abi3-macosx_11_0_arm64.whl.metadata (3.8 kB)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn->sentence-transformers)\n",
      "  Using cached joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn->sentence-transformers)\n",
      "  Downloading threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/christianweyer/Sources/gen-ai-customer-workshop-november-2024/.conda/lib/python3.11/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/christianweyer/Sources/gen-ai-customer-workshop-november-2024/.conda/lib/python3.11/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/christianweyer/Sources/gen-ai-customer-workshop-november-2024/.conda/lib/python3.11/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/christianweyer/Sources/gen-ai-customer-workshop-november-2024/.conda/lib/python3.11/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/christianweyer/Sources/gen-ai-customer-workshop-november-2024/.conda/lib/python3.11/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2025.1.31)\n",
      "Downloading sentence_transformers-3.4.1-py3-none-any.whl (275 kB)\n",
      "Downloading huggingface_hub-0.29.3-py3-none-any.whl (468 kB)\n",
      "Using cached torch-2.6.0-cp311-none-macosx_11_0_arm64.whl (66.5 MB)\n",
      "Using cached sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
      "Using cached transformers-4.49.0-py3-none-any.whl (10.0 MB)\n",
      "Using cached pillow-11.1.0-cp311-cp311-macosx_11_0_arm64.whl (3.1 MB)\n",
      "Using cached scikit_learn-1.6.1-cp311-cp311-macosx_12_0_arm64.whl (11.1 MB)\n",
      "Using cached scipy-1.15.2-cp311-cp311-macosx_14_0_arm64.whl (22.4 MB)\n",
      "Downloading fsspec-2025.3.0-py3-none-any.whl (193 kB)\n",
      "Using cached joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "Using cached safetensors-0.5.3-cp38-abi3-macosx_11_0_arm64.whl (418 kB)\n",
      "Downloading threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Downloading tokenizers-0.21.1-cp39-abi3-macosx_11_0_arm64.whl (2.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading filelock-3.18.0-py3-none-any.whl (16 kB)\n",
      "Using cached networkx-3.4.2-py3-none-any.whl (1.7 MB)\n",
      "Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Installing collected packages: mpmath, threadpoolctl, sympy, scipy, safetensors, Pillow, networkx, joblib, fsspec, filelock, torch, scikit-learn, huggingface-hub, tokenizers, transformers, sentence-transformers\n",
      "Successfully installed Pillow-11.1.0 filelock-3.18.0 fsspec-2025.3.0 huggingface-hub-0.29.3 joblib-1.4.2 mpmath-1.3.0 networkx-3.4.2 safetensors-0.5.3 scikit-learn-1.6.1 scipy-1.15.2 sentence-transformers-3.4.1 sympy-1.13.1 threadpoolctl-3.6.0 tokenizers-0.21.1 torch-2.6.0 transformers-4.49.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: numpy in /Users/christianweyer/Sources/gen-ai-customer-workshop-november-2024/.conda/lib/python3.11/site-packages (2.2.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install sentence-transformers\n",
    "%pip install numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. The data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [\n",
    "    'Wie lang muss ein Langbogen sein?',\n",
    "    'Wie lang muss ein Langbogen mindestens sein?',\n",
    "    'Mensch',\n",
    "    'Human',\n",
    "    'Die Hunde spielen mit dem Ball auf der Wiese',\n",
    "    'Das Rudel rollt das runde Spielgerät auf dem Rasen herum',\n",
    "    'The dogs play with the ball on the grass',\n",
    "    'Der Ballon fliegt in den Himmel',\n",
    "    'Die Taube kehrt zum Nest zurück',\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Create embeddings using Huggingface models\n",
    "\n",
    "Models can, for example, be found at the [https://huggingface.co/spaces/mteb/leaderboard](https://huggingface.co/spaces/mteb/leaderboard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.0218505  -0.01280628 -0.03129406 ... -0.0346019  -0.02073702\n",
      "  0.02748242]\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model_name = 'intfloat/multilingual-e5-large'\n",
    "embedding_model = SentenceTransformer(model_name)\n",
    "\n",
    "embeddings = embedding_model.encode(sentences)\n",
    "\n",
    "print(embeddings[0])\n",
    "for embedding in embeddings:\n",
    "    print(len(embedding))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0000: Wie lang muss ein Langbogen sein? <-> Wie lang muss ein Langbogen sein?\n",
      "0.9874: Wie lang muss ein Langbogen sein? <-> Wie lang muss ein Langbogen mindestens sein?\n",
      "0.7513: Wie lang muss ein Langbogen sein? <-> Mensch\n",
      "0.7260: Wie lang muss ein Langbogen sein? <-> Human\n",
      "0.7208: Wie lang muss ein Langbogen sein? <-> Die Hunde spielen mit dem Ball auf der Wiese\n",
      "0.7564: Wie lang muss ein Langbogen sein? <-> Das Rudel rollt das runde Spielgerät auf dem Rasen herum\n",
      "0.6436: Wie lang muss ein Langbogen sein? <-> The dogs play with the ball on the grass\n",
      "0.7806: Wie lang muss ein Langbogen sein? <-> Der Ballon fliegt in den Himmel\n",
      "0.7600: Wie lang muss ein Langbogen sein? <-> Die Taube kehrt zum Nest zurück\n",
      "1.0000: Wie lang muss ein Langbogen mindestens sein? <-> Wie lang muss ein Langbogen mindestens sein?\n",
      "0.7475: Wie lang muss ein Langbogen mindestens sein? <-> Mensch\n",
      "0.7197: Wie lang muss ein Langbogen mindestens sein? <-> Human\n",
      "0.7157: Wie lang muss ein Langbogen mindestens sein? <-> Die Hunde spielen mit dem Ball auf der Wiese\n",
      "0.7542: Wie lang muss ein Langbogen mindestens sein? <-> Das Rudel rollt das runde Spielgerät auf dem Rasen herum\n",
      "0.6409: Wie lang muss ein Langbogen mindestens sein? <-> The dogs play with the ball on the grass\n",
      "0.7697: Wie lang muss ein Langbogen mindestens sein? <-> Der Ballon fliegt in den Himmel\n",
      "0.7605: Wie lang muss ein Langbogen mindestens sein? <-> Die Taube kehrt zum Nest zurück\n",
      "1.0000: Mensch <-> Mensch\n",
      "0.8864: Mensch <-> Human\n",
      "0.7006: Mensch <-> Die Hunde spielen mit dem Ball auf der Wiese\n",
      "0.7186: Mensch <-> Das Rudel rollt das runde Spielgerät auf dem Rasen herum\n",
      "0.6541: Mensch <-> The dogs play with the ball on the grass\n",
      "0.7402: Mensch <-> Der Ballon fliegt in den Himmel\n",
      "0.7594: Mensch <-> Die Taube kehrt zum Nest zurück\n",
      "1.0000: Human <-> Human\n",
      "0.6764: Human <-> Die Hunde spielen mit dem Ball auf der Wiese\n",
      "0.7090: Human <-> Das Rudel rollt das runde Spielgerät auf dem Rasen herum\n",
      "0.6709: Human <-> The dogs play with the ball on the grass\n",
      "0.7206: Human <-> Der Ballon fliegt in den Himmel\n",
      "0.7268: Human <-> Die Taube kehrt zum Nest zurück\n",
      "1.0000: Die Hunde spielen mit dem Ball auf der Wiese <-> Die Hunde spielen mit dem Ball auf der Wiese\n",
      "0.8659: Die Hunde spielen mit dem Ball auf der Wiese <-> Das Rudel rollt das runde Spielgerät auf dem Rasen herum\n",
      "0.8993: Die Hunde spielen mit dem Ball auf der Wiese <-> The dogs play with the ball on the grass\n",
      "0.8146: Die Hunde spielen mit dem Ball auf der Wiese <-> Der Ballon fliegt in den Himmel\n",
      "0.7427: Die Hunde spielen mit dem Ball auf der Wiese <-> Die Taube kehrt zum Nest zurück\n",
      "1.0000: Das Rudel rollt das runde Spielgerät auf dem Rasen herum <-> Das Rudel rollt das runde Spielgerät auf dem Rasen herum\n",
      "0.8116: Das Rudel rollt das runde Spielgerät auf dem Rasen herum <-> The dogs play with the ball on the grass\n",
      "0.8299: Das Rudel rollt das runde Spielgerät auf dem Rasen herum <-> Der Ballon fliegt in den Himmel\n",
      "0.7906: Das Rudel rollt das runde Spielgerät auf dem Rasen herum <-> Die Taube kehrt zum Nest zurück\n",
      "1.0000: The dogs play with the ball on the grass <-> The dogs play with the ball on the grass\n",
      "0.7377: The dogs play with the ball on the grass <-> Der Ballon fliegt in den Himmel\n",
      "0.6611: The dogs play with the ball on the grass <-> Die Taube kehrt zum Nest zurück\n",
      "1.0000: Der Ballon fliegt in den Himmel <-> Der Ballon fliegt in den Himmel\n",
      "0.8201: Der Ballon fliegt in den Himmel <-> Die Taube kehrt zum Nest zurück\n",
      "1.0000: Die Taube kehrt zum Nest zurück <-> Die Taube kehrt zum Nest zurück\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def cosine_similarity(left, right):\n",
    "    return np.dot(left, right) / (np.linalg.norm(left) * np.linalg.norm(right))\n",
    "\n",
    "for i, left in enumerate(sentences):\n",
    "    for j, right in enumerate(sentences):\n",
    "        if j < i:\n",
    "            continue\n",
    "        similarity = cosine_similarity(embeddings[i], embeddings[j])\n",
    "        print(f'{similarity:.4f}: {left} <-> {right}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "polyglot_notebook": {
   "kernelInfo": {
    "defaultKernelName": "csharp",
    "items": [
     {
      "aliases": [],
      "name": "csharp"
     }
    ]
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
